# ğŸ± Kitten-TTS for ComfyUI

[![ComfyUI](https://img.shields.io/badge/ComfyUI-Custom%20Node-blue)](https://github.com/comfyanonymous/ComfyUI)
[![Python](https://img.shields.io/badge/Python-3.10%2B-green)](https://www.python.org/)
[![License](https://img.shields.io/badge/License-Apache%202.0-orange)](LICENSE)

A simple ComfyUI custom node for [KittenTTS](https://github.com/KittenML/KittenTTS) - an ultra-lightweight text-to-speech model. Works on **CUDA** and **CPU**.

<img width="1496" height="1015" alt="Screenshot 2026-02-19 194339" src="https://github.com/user-attachments/assets/6af8a500-0a48-47da-adff-e020a5437e88" />


## Demo

https://github.com/user-attachments/assets/d80120f2-c751-407e-a166-068dd1dd9e8d

## Features

- ğŸš€ **Ultra-lightweight**: Models from 19MB to 80MB
- ğŸ’» **CPU & CUDA**: Runs on any device, GPU optional
- ğŸ¯ **Single node**: All settings in one place
- ğŸ“¦ **Auto-download**: Models cached in `ComfyUI/models/kittentts/`
- âš¡ **Fast inference**: Real-time speech synthesis
- ğŸ¤ **8 voices**: 4 male, 4 female

## Installation

### Method 1: ComfyUI Manager (Recommended)
Search for "KittenTTS" in ComfyUI Manager and install.

### Method 2: Manual Install
```bash
cd ComfyUI/custom_nodes
git clone https://github.com/Saganaki22/ComfyUI-KittenTTS.git
```

### Dependencies

The node auto-installs dependencies on first run. For manual install:

**For CPU:**
```bash
pip install onnxruntime
```

**For CUDA GPU:**
```bash
pip install onnxruntime-gpu
```

## Models

| Model | Params | Size | Quality | Link |
|-------|--------|------|---------|------|
| kitten-tts-mini | 80M | 80MB | Best | [ğŸ¤— Download](https://huggingface.co/KittenML/kitten-tts-mini-0.8) |
| kitten-tts-micro | 40M | 41MB | Good | [ğŸ¤— Download](https://huggingface.co/KittenML/kitten-tts-micro-0.8) |
| kitten-tts-nano | 15M | 56MB | Lightweight | [ğŸ¤— Download](https://huggingface.co/KittenML/kitten-tts-nano-0.8) |
| kitten-tts-nano-int8 | 15M | 19MB | Smallest | [ğŸ¤— Download](https://huggingface.co/KittenML/kitten-tts-nano-0.8-int8) |

> âš ï¸ **Note**: Some users report issues with the int8 quantized model. We recommend the mini or micro versions for best results.

## Usage

The node is simple - just one node with all settings:

### Inputs

| Input | Type | Default | Description |
|-------|------|---------|-------------|
| `model_name` | Dropdown | mini-0.8 (80M) | Model size/quality |
| `device` | Dropdown | auto | auto/cuda/cpu |
| `text` | String | - | Text to synthesize |
| `voice` | Dropdown | Jasper | Voice selection |
| `speed` | Float | 1.0 | Speech speed (0.5-2.0) |
| `keep_loaded` | Boolean | True | Keep model in memory |
| `output_stereo` | Boolean | False | Stereo output |
| `clean_text` | Boolean | True | Normalize text |
| `custom_model` | String | "" | Custom HF model ID |

### Voices

**Male:** Jasper, Bruno, Hugo, Leo  
**Female:** Bella, Luna, Rosie, Kiki

### Example

Just add the **ğŸ± KittenTTS** node, type your text, select a voice, and connect the audio output to your pipeline.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    ğŸ± KittenTTS         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ model: mini-0.8 (80M)   â”‚
â”‚ device: auto            â”‚
â”‚ text: "Hello world!"    â”‚
â”‚ voice: Jasper           â”‚
â”‚ speed: 1.0              â”‚
â”‚ keep_loaded: True       â”‚
â”‚ output_stereo: False    â”‚
â”‚ clean_text: True        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ audio â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚  â†’ Connect to audio nodes
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Model Storage

Models are downloaded to: `ComfyUI/models/kittentts/<model_name>/`

You can create symlinks to this folder if you want to share models between ComfyUI installations.

## Troubleshooting

### "CUDA out of memory"
- Switch to a smaller model (nano or micro)
- Set `keep_loaded` to False
- Use CPU device

### "onnxruntime not found"
```bash
# For CPU
pip install onnxruntime

# For CUDA
pip install onnxruntime-gpu
```

### "No module named 'kittentts'"
The bundled wheel should auto-install. If not:
```bash
pip install https://github.com/KittenML/KittenTTS/releases/download/0.8/kittentts-0.8.0-py3-none-any.whl
```

## Links

- **Original KittenTTS Repo**: [https://github.com/KittenML/KittenTTS](https://github.com/KittenML/KittenTTS)
- **HuggingFace Models**: [https://huggingface.co/KittenML](https://huggingface.co/KittenML)
- **Discord**: [Join KittenML Discord](https://discord.com/invite/VJ86W4SURW)
- **Demo Video**: [Watch on GitHub](https://github.com/KittenML/KittenTTS)

## Credits

- KittenTTS by [KittenML](https://github.com/KittenML)
- ComfyUI node by [Saganaki22](https://github.com/Saganaki22)

## License

Apache 2.0 - See [LICENSE](LICENSE) for details.
